{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# Gensim\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\n\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn import decomposition\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.model_selection import train_test_split\n\n#For lemmatizaton\nimport spacy\n\n# Plotting tools\nimport pyLDAvis\nimport pyLDAvis.gensim  # don't skip this\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/topic-modelling-principal-data/principal_data.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/topic-modelling-principal-data/principal_data.csv')\ntrain.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"  review_date                                       review_title  \\\n0  2019-11-11                                  Awesome Workplace   \n1  2019-11-06  One of the bestest captive organization to wor...   \n2  2019-10-29                             Best work life balance   \n3  2019-11-10                           Principal global service   \n4  2019-10-26                                  Senior Consultant   \n\n                                 author_active location  overall_rating  \\\n0        Current Employee - Software Developer     Pune             5.0   \n1  Former Employee - Senior Programmer Analyst     Pune             5.0   \n2                 Current Employee - Tech Lead     Pune             5.0   \n3                 Current Employee - Tech Lead     Pune             3.0   \n4        Current Employee - Anonymous Employee     Pune             3.0   \n\n   recommends           outlook  \\\n0  Recommends  Positive Outlook   \n1  Recommends  Positive Outlook   \n2  Recommends  Positive Outlook   \n3         NaN               NaN   \n4  Recommends  Positive Outlook   \n\n                                         review_text  \\\n0  I have been working at Principal Financial Gro...   \n1  I worked at Principal Financial Group full-tim...   \n2  I have been working at Principal Financial Gro...   \n3  I have been working at Principal Financial Gro...   \n4  I have been working at Principal Financial Gro...   \n\n                                                pros  \\\n0   Work life balance, employee friendly, good work.   \n1  Work life balance\\r\\nGreat Learning\\r\\nFree Tr...   \n2                              All you can think of.   \n3  Employee benefits, open culture. Moving to New...   \n4    Great leadership and vision and good colleagues   \n\n                                                cons  \n0  There are no cons as from my personal experience.  \n1  Politics\\r\\nFew people consider it there home ...  \n2            Slightly backdated technology used here  \n3  Laterals are paid very less as compared to one...  \n4  Being a financial organization to much IT focu...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_date</th>\n      <th>review_title</th>\n      <th>author_active</th>\n      <th>location</th>\n      <th>overall_rating</th>\n      <th>recommends</th>\n      <th>outlook</th>\n      <th>review_text</th>\n      <th>pros</th>\n      <th>cons</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-11-11</td>\n      <td>Awesome Workplace</td>\n      <td>Current Employee - Software Developer</td>\n      <td>Pune</td>\n      <td>5.0</td>\n      <td>Recommends</td>\n      <td>Positive Outlook</td>\n      <td>I have been working at Principal Financial Gro...</td>\n      <td>Work life balance, employee friendly, good work.</td>\n      <td>There are no cons as from my personal experience.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-11-06</td>\n      <td>One of the bestest captive organization to wor...</td>\n      <td>Former Employee - Senior Programmer Analyst</td>\n      <td>Pune</td>\n      <td>5.0</td>\n      <td>Recommends</td>\n      <td>Positive Outlook</td>\n      <td>I worked at Principal Financial Group full-tim...</td>\n      <td>Work life balance\\r\\nGreat Learning\\r\\nFree Tr...</td>\n      <td>Politics\\r\\nFew people consider it there home ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-10-29</td>\n      <td>Best work life balance</td>\n      <td>Current Employee - Tech Lead</td>\n      <td>Pune</td>\n      <td>5.0</td>\n      <td>Recommends</td>\n      <td>Positive Outlook</td>\n      <td>I have been working at Principal Financial Gro...</td>\n      <td>All you can think of.</td>\n      <td>Slightly backdated technology used here</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-11-10</td>\n      <td>Principal global service</td>\n      <td>Current Employee - Tech Lead</td>\n      <td>Pune</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>I have been working at Principal Financial Gro...</td>\n      <td>Employee benefits, open culture. Moving to New...</td>\n      <td>Laterals are paid very less as compared to one...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-10-26</td>\n      <td>Senior Consultant</td>\n      <td>Current Employee - Anonymous Employee</td>\n      <td>Pune</td>\n      <td>3.0</td>\n      <td>Recommends</td>\n      <td>Positive Outlook</td>\n      <td>I have been working at Principal Financial Gro...</td>\n      <td>Great leadership and vision and good colleagues</td>\n      <td>Being a financial organization to much IT focu...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting all the columns name to lower case for easy access\ntrain.columns  = train.columns.str.lower()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import wordnet\n\ndef get_wordnet_pos(pos_tag):\n    if pos_tag.startswith('J'):\n        return wordnet.ADJ\n    elif pos_tag.startswith('V'):\n        return wordnet.VERB\n    elif pos_tag.startswith('N'):\n        return wordnet.NOUN\n    elif pos_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN\n    \nimport string\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import WhitespaceTokenizer\nfrom nltk.stem import WordNetLemmatizer\n\ndef clean_text(text):\n    # lower text\n    text = text.lower()\n    # tokenize text and remove puncutation\n    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n    # remove words that contain numbers\n    text = [word for word in text if not any(c.isdigit() for c in word)]\n    # remove stop words\n    stop_words = stopwords.words('english')\n    not_stopwords = {'no', 'not', 'but', 'all', 'think', 'of'}\n    final_stop_words = set([word for word in stop_words if word not in not_stopwords])\n    text = [x for x in text if x not in final_stop_words]\n    # remove empty tokens\n    text = [t for t in text if len(t) > 0]\n    # pos tag text\n    pos_tags = pos_tag(text)\n    # lemmatize text\n    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n    # remove words with only one letter\n    text = [t for t in text if len(t) > 1]\n    # join all\n    text = \" \".join(text)\n    return(text)\n\n# clean text data\ntrain[\"pros\"] = train[\"pros\"].apply(lambda x: clean_text(x))\ntrain[\"cons\"] = train[\"cons\"].apply(lambda x: clean_text(x))\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews = train.copy()\nreviews['pros'] = [x.replace(\"\\r\\n\",\"\") for x in reviews['pros']]\n\nreviews['cons'] = [x.replace(\"\\r\\n\",\"\") for x in reviews['cons']]\nreviews['feedback'] = reviews['pros'] + \" \" + reviews['cons']\nreviews['feedback'][0]\n","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"'work life balance employee friendly good work no con personal experience'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews['sentiment']=reviews['overall_rating'].apply(lambda x: 2 if int(x)>3 else (1 if int(x) ==3 else 0))","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews.drop(['pros','location','review_date', 'cons', 'author_active', 'overall_rating', 'review_title', 'outlook', 'recommends', 'review_text'], axis = 1, inplace = True)\nreviews.head(n=5)","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"                                            feedback  sentiment\n0  work life balance employee friendly good work ...          2\n1  work life balancegreat learningfree transporto...          2\n2      all think of slightly backdate technology use          2\n3  employee benefit open culture move new technol...          1\n4  great leadership vision good colleague financi...          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feedback</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>work life balance employee friendly good work ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>work life balancegreat learningfree transporto...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all think of slightly backdate technology use</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>employee benefit open culture move new technol...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>great leadership vision good colleague financi...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add number of characters column\nreviews[\"nb_chars\"] = reviews[\"feedback\"].apply(lambda x: len(x))\n\n# add number of words column\nreviews[\"nb_words\"] = reviews[\"feedback\"].apply(lambda x: len(x.split(\" \")))","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nNext, we add some simple metrics for every text:\nnumber of characters in the text\nnumber of words in the text \"\"\"\n\n# create doc2vec vector columns\nfrom gensim.test.utils import common_texts\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\ndocuments = [TaggedDocument(doc, [i]) for i, doc in enumerate(reviews[\"feedback\"].apply(lambda x: x.split(\" \")))]\n\n# train a Doc2Vec model with our text data\nmodel = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n\n# transform each document into a vector data\ndoc2vec_df = reviews[\"feedback\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\ndoc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\nreviews = pd.concat([reviews, doc2vec_df], axis=1)","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next step consist in extracting vector representations for every review. The module Gensim creates a numerical vector representation of every word in the corpus by using the contexts in which they appear (Word2Vec). This is performed using shallow neural networks. What’s interesting is that similar words will have similar representation vectors.\nEach text can also be transformed into numerical vectors using the word vectors (Doc2Vec). Same texts will also have similar representations and that is why we can use those vectors as training features.\nWe first have to train a Doc2Vec model by feeding in our text data. By applying this model on our reviews, we can get those representation vectors."},{"metadata":{"trusted":true},"cell_type":"code","source":"# add tf-idfs columns\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(min_df = 10)\ntfidf_result = tfidf.fit_transform(reviews[\"feedback\"]).toarray()\ntfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\ntfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\ntfidf_df.index = reviews.index\nreviews = pd.concat([reviews, tfidf_df], axis=1)\nreviews.head(n=2)","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"                                            feedback  sentiment  nb_chars  \\\n0  work life balance employee friendly good work ...          2        72   \n1  work life balancegreat learningfree transporto...          2       232   \n\n   nb_words  doc2vec_vector_0  doc2vec_vector_1  doc2vec_vector_2  \\\n0        11         -0.048265         -0.111533         -0.099987   \n1        26          0.350067         -0.430682         -0.202887   \n\n   doc2vec_vector_3  doc2vec_vector_4  word_ability  ...  word_within  \\\n0         -0.034999          0.024691           0.0  ...          0.0   \n1          0.063401          0.299872           0.0  ...          0.0   \n\n   word_without  word_woman  word_work  word_worker  word_would  word_year  \\\n0      0.000000         0.0   0.290340          0.0         0.0        0.0   \n1      0.353405         0.0   0.342206          0.0         0.0        0.0   \n\n   word_yet  word_you  word_young  \n0       0.0       0.0         0.0  \n1       0.0       0.0         0.0  \n\n[2 rows x 388 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feedback</th>\n      <th>sentiment</th>\n      <th>nb_chars</th>\n      <th>nb_words</th>\n      <th>doc2vec_vector_0</th>\n      <th>doc2vec_vector_1</th>\n      <th>doc2vec_vector_2</th>\n      <th>doc2vec_vector_3</th>\n      <th>doc2vec_vector_4</th>\n      <th>word_ability</th>\n      <th>...</th>\n      <th>word_within</th>\n      <th>word_without</th>\n      <th>word_woman</th>\n      <th>word_work</th>\n      <th>word_worker</th>\n      <th>word_would</th>\n      <th>word_year</th>\n      <th>word_yet</th>\n      <th>word_you</th>\n      <th>word_young</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>work life balance employee friendly good work ...</td>\n      <td>2</td>\n      <td>72</td>\n      <td>11</td>\n      <td>-0.048265</td>\n      <td>-0.111533</td>\n      <td>-0.099987</td>\n      <td>-0.034999</td>\n      <td>0.024691</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.290340</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>work life balancegreat learningfree transporto...</td>\n      <td>2</td>\n      <td>232</td>\n      <td>26</td>\n      <td>0.350067</td>\n      <td>-0.430682</td>\n      <td>-0.202887</td>\n      <td>0.063401</td>\n      <td>0.299872</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.353405</td>\n      <td>0.0</td>\n      <td>0.342206</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 388 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\npickle.dump(tfidf, open('transform.pkl', 'wb'))","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"\"\"Finally we add the TF-IDF (Term Frequency — Inverse Document Frequency) values for every word and every document.\nBut why not simply counting how many times each word appears in every document? The problem with this method is that it doesn’t take into account the relative importance of words in the texts. A word that appears in almost every text would not likely bring useful information for analysis. On the contrary, rare words may have a lot more of meanings.\nThe TF-IDF metric solves this problem:\nTF computes the classic number of times the word appears in the text\nIDF computes the relative importance of this word which depends on how many texts the word can be found\nWe add TF-IDF columns for every word that appear in at least 10 different texts to filter some of them and reduce the size of the final output.\"\"\""},{"metadata":{"trusted":true},"cell_type":"code","source":"label = \"sentiment\"\nignore_cols = [label, \"feedback\"]\nfeatures = [c for c in reviews.columns if c not in ignore_cols]\nX_train, X_test, y_train, y_test = train_test_split(reviews[features], reviews[label], test_size = 0.20, random_state = 42)\n","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n# train a random forest classifier\nrf = RandomForestClassifier(n_estimators = 100, random_state = 42)\nrf.fit(X_train, y_train)\n\n# show feature importance\nfeature_importances_df = pd.DataFrame({\"feature\": features, \"importance\": rf.feature_importances_}).sort_values(\"importance\", ascending = False)\nfeature_importances_df.head(20)","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"              feature  importance\n4    doc2vec_vector_2    0.026970\n212   word_management    0.025564\n5    doc2vec_vector_3    0.025374\n6    doc2vec_vector_4    0.023405\n3    doc2vec_vector_1    0.023203\n2    doc2vec_vector_0    0.023184\n0            nb_chars    0.020699\n379         word_work    0.018635\n1            nb_words    0.017903\n236           word_no    0.017311\n145         word_good    0.015501\n239          word_not    0.013718\n146        word_great    0.012270\n68       word_company    0.012049\n195         word_life    0.011355\n244       word_office    0.010803\n35       word_balance    0.010393\n310       word_salary    0.010290\n242           word_of    0.009034\n196         word_like    0.007707","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>doc2vec_vector_2</td>\n      <td>0.026970</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>word_management</td>\n      <td>0.025564</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>doc2vec_vector_3</td>\n      <td>0.025374</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>doc2vec_vector_4</td>\n      <td>0.023405</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>doc2vec_vector_1</td>\n      <td>0.023203</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>doc2vec_vector_0</td>\n      <td>0.023184</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>nb_chars</td>\n      <td>0.020699</td>\n    </tr>\n    <tr>\n      <th>379</th>\n      <td>word_work</td>\n      <td>0.018635</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>nb_words</td>\n      <td>0.017903</td>\n    </tr>\n    <tr>\n      <th>236</th>\n      <td>word_no</td>\n      <td>0.017311</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>word_good</td>\n      <td>0.015501</td>\n    </tr>\n    <tr>\n      <th>239</th>\n      <td>word_not</td>\n      <td>0.013718</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>word_great</td>\n      <td>0.012270</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>word_company</td>\n      <td>0.012049</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>word_life</td>\n      <td>0.011355</td>\n    </tr>\n    <tr>\n      <th>244</th>\n      <td>word_office</td>\n      <td>0.010803</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>word_balance</td>\n      <td>0.010393</td>\n    </tr>\n    <tr>\n      <th>310</th>\n      <td>word_salary</td>\n      <td>0.010290</td>\n    </tr>\n    <tr>\n      <th>242</th>\n      <td>word_of</td>\n      <td>0.009034</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>word_like</td>\n      <td>0.007707</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.score(X_test, y_test)","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"0.6624203821656051"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'senti_model.pkl'\npickle.dump(rf,open(filename, 'wb'))","execution_count":20,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}